---
title: Simulation View of Causality
author: ''
date: '2019-04-13'
slug: understanding-pearl-s-front-door-magic-part-I
categories:
  - Causality
tags:
  - front-door criterion
  - do calculus
  - causal conditioning
---
<style>
div.blue pre.r { background-color:azure; }
div.blue pre { background-color:#ffe2dd; }
</style>

_I try to present an intuitive account of causal reasoning and the important notions of causal conditioning and counterfactuals without resorting to some of the formalities of do-calculus, d-separation, couterfactual notation and the like._

First a little background to set up our running example. 

The amount of energy generated by photovoltaic solar power-plants is decreased by not an insignificant amount when dirt and other particulates collect on the panels. This, so-called _soiling_ problem is especially acute in dusty desert regions which are otherwise ideal sites for solar plants, because the sun shines bright when there aren't many clouds in sight. Consequently plant operators are always on the lookout for cheap and effective panel soiling mitigation strategies.

Imagine that a meticulous solar-scientist named Sol is tasked with estimating the effect on the energy production of weekly washing of the panels in a fleet of solar power plants. Assume that he has at hand data on weekly aggregates of days of rainfall (denoted $R$), weekly average cloud-cover (denoted $C$), and total weekly energy production from the solar fleet (denoted $E$). Sol reasons that if he could estimate the effect of having _at least_ one day of rain on the amount of energy produced, he could use it as a proxy for weekly washing.

Before tackling the panel washing problem, Sol analyzes his data and incorporates known physical principles to construct a _generative model_ for the data generating process. (Recall that a generative model is a story that we believe about a physical process written down in the language of probabilities.)

Commonsense tells Sol that clouds cause rain and that clouds cause a drop in energy production, while rain increases production by washing away the dirt on the panels. A graphical depiction (called the _causal graph_) of Sol's mental model of the causal story hidden in the data is

![](/post/2019-04-13-understanding-pearl-s-front-door-magic_files/solar_graph.png){width=30%}

He estimates the necessary parameters of his model from the data, and implements his model as shown below to simulate behaviors or instances of the physical proess (i.e, generate joint samples of $(C, R, E)$.

<div class = "blue">
```{r}
model = function(){
  c = runif(1, min=0, max=0.3)                         ## cloud-cover: C ~ Uniform(0, 0.3)
  r = floor(7 *(4*c^2 + runif(1, min=0, max=0.1)))     ## rainy-days: R = f_R(C, noise)
  e = 500 * (1 - 2*c + 0.1 * r) + 10 * rnorm(1)        ## energy: E = f_E(c, r, noise) 
  return(data.frame(C=c, R=r, E=e))
}
```
</div>

Ignoring the particular functional forms we can notice that the order of computations follows the _topological_ order of the variables in the graph above. The average cloudiness ($C$) is a random variable, the rainy days variable ($R$) is some function of $C$ and noise, and the energy ($E$) is a function of $C$, $E$ and different noise. The noisy functions attempt to capture both measurement and modeling errors. 

Note that because of the noise variables, the above program defines a joint distribution over the triple $(C, R, E)$. In fact, Sol can compute the conditional density $P(E | R=r)$ by simply sampling from the simulator, filtering for $R=r$ and fitting a density estimator to the energy values on the filtered samples. The conditional densities look as below

```{r echo=F}
library(ggplot2)
library(knitr)
df <- do.call(rbind, lapply(1:10000, function(i) model()))
df$R <- factor(df$R)
ggplot(aes(E, fill = R, color = R), data=df) + geom_density(alpha = 0.1)+ggtitle("P(E | R)")#+theme_bw() 
```

According to the distribution defined by the simulator the hightest energy production tends to happen in weeks with no rain. This is perhaps mildly surpising for someone who hasn't heard of _confounding_; the data shows this because both rain and energy are affected by their common cause -- cloudiness.

Sol rewrites his simulator making the noise variables explicit as well as adding some optional arguments to override some of the computations as follows

<div class = "blue">
```{r}
model = function(do_c, do_r, do_e, do_uc, do_ur, do_ue){
  uc = ifelse(missing(do_uc), runif(1), do_uc)       ## Uc ~ Uniform(0, 1)
  c = ifelse(missing(do_c), uc * 0.3, do_c)          ## C = Uc * 0.3 
  
  ur = ifelse(missing(do_ur), runif(1), do_ur)       ## Ur ~ Uniform(0, 1)
  r = ifelse(missing(do_r), 
             floor(7 *(4*c^2 + ur * 0.1)), do_r)     ## R = f_R(C, Ur)
  
  ue = ifelse(missing(do_ue), rnorm(1), do_ue)       ## Ue ~ Normal(0, 1)
  e = ifelse(missing(do_e), 
        500 * (1 - 2*c + 0.1 * r) + 10 * ue,
        do_e)                                        ## E = f_E(C, R, Ue)
  
  return(data.frame(C=c, R=r, E=e, UC=uc, UR=ur, UE=ue))
}

generate = function(num_samples, ...){
  df <- do.call(rbind, lapply(1:num_samples, function(i) model(...)))
  df$R <- factor(df$R, levels=0:3)
  df
}
```
</div>

Although the code now looks more complicated it implements exactly the same model as the version before it, albeit allowing Sol to arbitrarily set any of the variables to values of his choosing. Setting the function argument "do_x" allows Sol to surgically replace the value of variable $X$ in his simulation from what it would have been otherwise. (The "generate" function is just a helper to sample from the simulator.)

The underlying model can more clearly be depicted as 

![](/post/2019-04-13-understanding-pearl-s-front-door-magic_files/solar_graph_noise.png){width=30%}

The randomness in the simulator is owed only to the _indepdendent_ noise variables $U_C$, $U_R$ and $U_E$; the variables $C$, $R$ and $E$ are _deterministic_ functions of the variables they _listen to_ (to borrow a phrase that Judea Pearl populalized). We can think of the values taken by the noise variables $U_C$, $U_R$ and $U_E$ for any sample as _defining_ that sample. They give the sample its _individuality_ as it were.

A model with this structure is termed a _Structural Causal Model_, which I only mention to prime the reader to its encounter in future wanderings.    

The awesome power conferred by a simulator in one's possession brings a temptation to meddle that is hard to resist even for an old testament god, let alone a mere solar scientist. Sol dutifully proceeds to meddle.

Interventions
-------------
To determine the _causal_ effect of rain on energy production, Sol needs to simulate the process in a _parallel universe_ where rain can be controlled independently of its influence from cloudiness. (He is after all investigating the effect panel washing would have on energy production, and cloudiness would not affect the decision to wash.) He intervenes to set the rain variable to different values as follows

<div class = "blue">
```{r cache=T}
n <- 10000
#generate n samples each by setting do_r to different values 0, 1, 2, or 3
df_intervention <- do.call(rbind, lapply(0:3,function(r) generate(n, do_r = r)))
ggplot(aes(E, fill = R, color = R), data=df_intervention) + geom_density(alpha = 0.1)+ggtitle("P(E | do(R))")
```
</div>

The quantity $P(E|do(R=r))$ is shorthand for the distribution of $E$ produced when Sol samples from his simulator by setting the "do_r" argument to the value $r$. 

Contrary to the conditional probabilities estimated before, this simulation shows that more rain _causes_ more energy. The so-called __interventional distribution__ $P(E | do(R =r))$ is obtained by __causal conditioning__ and is in general _different_ from the __Bayesian conditional distribution__ $P(E|R=r)$. 

A graphical representation of the way the process unfolds in the parallel universe (and of the program that simulates it) is

![](/post/2019-04-13-understanding-pearl-s-front-door-magic_files/solar_graph_do_r.png){width=30%}

All the arrows pointing to the node $R$ have been severed and its value is set to $r$. This is the essence of what it means to intervene -- we remove any other causal influences on the variable on which we are intervening. This is why Bayesian conditioning differs from causal conditioning -- when we causally condition, we are hypothesizing a different universe which is running a _different program_, consequently producing a _different distribution_ over the observables. 

One way to internalize the conceptual difference between the two kinds of conditioning is to note that causal conditioning is carried out by setting the "do" argument of the simulator, whereas Bayesian conditioning is carried out by sampling and filtering. For example, to estimate $P(E | do(R =r), C=c)$ we sample from the simulator by setting argument do_r to $r$, then filter the samples for $C =c$ and compute the histogram over $E$ from the filtered samples.

Now might be a good juncture break for rest and take in the scenery. As a warmup for what is coming next the reader might want to mull the following questions. Looking at the order of the calculations in Sol's simulator above may help.

- What is $P(E | do(R=r), do(U_R=u_r))$?
- How does $P(E|do(C = c))$ relate $P(E|C=c)$?
- What is the interpretation of $P(E|do(U_R = u_r))$?

Counterfactuals
---------------
As noted above for any one sample from the model, the particular values assumed by the random variables $U_C$, $U_R$ and $U_E$ for that sample completely specify it, and together represent a particular week in our universe. In other words, we can _define_ an individual week by _assigning_ specific values to these random variables. 

Let us generate a _single_ sample from, Sol's simulator. 

<div class = "blue">
```{r comment='', results='asis'}
set.seed(0)
week_a = generate(1)                     ## generate one sample
kable(week_a, format="html", digits = 2) ## print the sample
```
</div>

We can now ask the following question. _What would the energy prodcution have been in this week had it not rained at all?_ This is what we call a _counterfactual_; a question about events in a universe where they unfolded contrary to those in our actual factual universe. 

What does this counterfactual question mean? Colloquially it means, "_all else being equal_ how would the energy production $E$ have changed to if we had set $R$ to zero?". Clearly the "all else" does not include $E$ itself. We only mean that while not changing anything that gives this week its _individuality_ how does intervening on $R$ affect $E$. 

As we said before, an instance derives its individuality from the values assumed by the noise variables $U_C$, $U_R$ and $U_E$. Therefore the way to answer the counterfactual is to run the simulator with the arguments do_uc, do_ur, do_ue set to 0.9, 0.27, and -0.33 respectively _and_ to set do_r to 0. 

<div class = "blue">
```{r comment='', results='asis'}
counterfactual_week_a = generate(1, do_uc=0.9, do_ur=0.27, do_ue=-0.33, do_r=0)    ## counterfactual!
kable(counterfactual_week_a, format="html", digits = 2) 
```
</div>

We estimate that the energy production _would have been_ 227 Mwh ((instead of the 328 Mwh that was _actually observed_) had it not rained _in that particular week_.  Note that because all the noise variables are fixed there is no stochasticity left in the simulator -- it would produce exactly the same vector of observations no matter how many times we run it.

We can perform this $do(R=0)$ counterfactual computation for every instance in our universe. Because of the lack of stochasticity in counterfactual sample, there is a one-to-one correspondence between every example in the factual universe and those in the counterfactual universe. 

I will annotate the column names of the counterfactual samples by a subscript "r" (or "_r" in the column names) to indicate that these measurements are made in the parallel universe where $R$ was intervened on. 

<div class = "blue">
```{r comment='', results='asis', cache=T}
n = 10000
weeks_actual = generate(n) 
weeks_counterfactual = do.call(rbind, lapply(1:n,function(i) 
           generate(1, do_uc=weeks_actual$UC[i], do_ur=weeks_actual$UR[i], do_ue=weeks_actual$UE[i], do_r=0)))
names(weeks_counterfactual) = paste0(names(weeks_counterfactual), "_r") ## rename counterfactual variables
df_counterfactual = cbind(weeks_actual,weeks_counterfactual)
kable(df_counterfactual[1:10,], format="html", digits = 2) 
```
</div>

As we expect, for all cases where $R=0$, the counterfactual values for all the variables equal their actual values (a no-rain week in our universe would see no difference in the counterfactual universe where we force it to not rain). Also since the noise variables in the counterfactual universe have the same values as those in ours the subscript "_r" is unnecessary. 


Let us compare the causal conditional distribution $P(E | do(R=0))$ with the distribution of the counterfactual energy variable $E_r$ in the above table.

<div class = "blue">
```{r}
plot(density(df_intervention$E[df_intervention$R == 0]), col="blue",
     main = "R = 0", xlab = "E")
lines(density(df_counterfactual[["E_r"]]), col="red")
```
</div>
Perhaps surprisingly they turn out to be the same. A moment's reflection about how these two distributions were generated from Sol's simulator should convince the reader that the inteventional distribution obtained by causal conditioning is _precisely_ the summary of counterfactuals over all the instances. In fact the interventional distribution $P(E|do(R=r))$ is could more precisely be written as $P(E_r|R_r = r)$. (Note that this is __non-standard notation__ but it makes it easier for me to keep everything straight.)

The notion of counterfactuals is therefore more fundamental than the notion of causal conditioning or interventional distributions. All interventional questions could be answered by generating counterfactual samples, and then appropriately conditioning and aggregating them.

We can ask very general conditional questions about this counterfactual universe. For example, "for a week with low energy production, what is the distribution of the decrease in energy production if we intervened to make it not rain?" Answer: $P(E - E_r|R_r=0, E < e)$. Filter the above table for $E < e$ and compute the histogram over the difference $E-E_r$ on the remaining rows.

We have been asking counterfactual questions about instances generated from the simulator. What if Sol wanted take a particular week from his dataset and ask what the energy production would have been had it not rained in _that week_? Since he only has access to the $C$, $R$ and $E$ variables for that week but _not_ the noise ($U_.$) variables, he cannot follow our simple procedure of running simulator with arguments do_r=0 and do_uc, do_ur and do_ue set to the particular values. The procedure he needs to follow is to first _estimate_ the _posterior distribution_ over noise variables from the probabilistic model (which the simulator mirrors) conditioned on the observations for that week, and use samples from this posterior as arguments for the simulator. In pseudocode 

<div class = "blue">
```{R eval=F}
sample_counterfactual(c, r, e){ ## single week observation = (c, r, e)
  for(i in 1:num_samples) {
    uc, ur, ue = sample_from(P(UC, UR, UE | C=c, R=r, E=e))
    counterfactual_samples_E[i] = generate(1, do_r=0, do_uc=uc, do_ur=ur, do_ue=ue)
  }
  return(counterfactual_samples_E)
}
```
</div>

Note that this procedure is no longer one-to-one; for a given week we obtain a _distribution_ over the energy production in the counterfactual "no-rain" universe. 

To summarize, the procedure to answer causal questions is to translate it into a description of the variables to _fix_ in the simulator, and of how to filter and aggregate the generated samples. In the happy situation where we have a fully-fledged model (and hence a simulator) that can generate joint samples of all the variables in the physical process the preceeding discussion is (almost) the entire story.


Unhappy Situations
------------------




