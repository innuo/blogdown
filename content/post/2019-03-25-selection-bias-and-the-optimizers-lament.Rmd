---
title: Selection Bias and the Disappointed Optimizer
author: ''
date: '2019-03-25'
slug: selection-bias-and-the-optimizers-lament
categories:
  - Optimization
tags:
  - Selection bias
---

_Wherein I introduce and explain the well-studied mechanism behind the pervasive phenomenon in life of things being just a bit worse than expected. I will walk through some of the discussion in two excellent articles, [The Optimizerâ€™s Curse: Skepticism and Postdecision Surprise in Decision Analysis](https://pdfs.semanticscholar.org/ce61/396a4abe1da265f4b5d3f05d11fd206c40f7.pdf) by Smith and Winkler and [Estimating the Maximum Expected Value: An Analysis of (Nested) Cross Validation and the Maximum Sample Average](https://arxiv.org/pdf/1302.7175.pdf) by van Hasselt._

Have you noticed that the checkout lanes you choose at the grocery store tends to be slower than you expected, the products you order off Amazon disappoint, and your second dates are not as exciting as your firsts? If you have, and suspect that the universe is conspiring against you, let me assure you that your suspicions are well-founded. The fundamental laws of probability have indeed been arrayed to scupper your satisfaction. If you haven't noticed any such conspiracy, I congratulate you on either your consistent practice of Zen Buddhism or on your finely tuned skepticism about things.

The mechanism that may explain this seeming conspiracy, phenomena as diverse as the the replication crisis in social sciences and oil wells producing below expectations, and also superstitions like the Sports Illustrated cover jinx is what Smith and Winker call _Optimizer's Curse_. Let's look a bit closer at the mechanism (using notation slightly different from Smith and Winkler).

Imagine that you are selecting from $n$ options, $1, \ldots, n$. Let the _true_ values of these $n$ options to you be as the vector $\mu = (\mu_1, \ldots, \mu_n)$.  If these true values were known to you, then you would choose option $m$ where $m = \mbox{argmax}_i\, \mu_i$. 

Instead assume that you only have _estimates_ ($V = (v_1, \ldots, v_n)$) of the true values. Further assume that the estimates are _unbiased_. That is, on average each $v_i$ neither overestimates nor underestimates its corresponding true value $\mu_i$. An obvious strategy now is for you choose to go with option $k = \mbox{argmax}_i\, v_i$. That is, you select the option that has the largest estimate of value. After the choice is made, the true value $\mu_k$ is revealed to you. We want to know what the _surprise_ $\mu_k - v_k$ is, on average.

We have
$$\mu_k - v_k \leq \mu_k - v_m \leq \mu_m - v_m$$
The first inequality is because $v_k \geq v_m$ (that's why you chose option $k$) and the second inequality is because $\mu_m \geq \mu_k$ because $m^{th}$ option is the best (unbeknowst to you.)

Now taking expectations with respect to $V$ we have
$$ E[\mu_k - v_k ] \leq E[\mu_m - v_m] = 0$$
The equality of the second term to zero is due to our assumption that the estimates are all (and in particular the $m^{th}$ one is) unbiased. The expected surprise is therefore non-positive. In fact, it is zero only when the probability $P(k = m) = 1$. That is, if there is a chance that you can make a wrong choice based on the estimates, then your suprises are on average unpleasant. 

Disappointment Mitigation
-------------------
If you knew that the true values are being generated from a _known_ distribution $P(\mu)$, the bias can be _completely_ eliminated by turning the Bayesian crank. 

In this case the _generative model_ for our problem can be written as (read $\sim$ "is distributed as")
$$\begin{aligned}
\mu &\sim P(\mu)\\
v_i &\sim P(.| \mu_i)
\end{aligned}
$$

The procedure to follow under this model is to first estimate the posterior means $E[\mu|V] \triangleq (\hat{\mu}_1, \ldots, \hat{\mu}_n)$ and then select the "best" option based on the posterior means, $k = \mbox{argmax}_i\, \hat{\mu}_i = \mbox{argmax}_i\, E[\mu_i|V]$. 

What is the expected surprise under this model? To make things clear I will make it explicit as to what variables the expectations are over.

$$\begin{aligned}
E[\mu_k - \hat{\mu}_k] &\triangleq E_{\mu, V}[\mu_k - \hat{\mu}_k] \\
&= E_V[E_\mu[\mu_k - \hat{\mu}_k|V]]  \\
&= E_V[E_\mu[\mu_k|V] - \hat{\mu}_k] \\
&= E_V[\hat{\mu}_k  - \hat{\mu}_k] = 0
\end{aligned}$$ 

The first line is just the definition of what we mean by average surprise. The second line uses the law of total expectation. The third line uses the fact that since $\hat{\mu}_k$ is a function of $V$, it is a constant when $V$ is fixed. The last line is from the definition of the posterior estimate $\hat{\mu}_k$. 

Therefore, if you use the posterior estimates of as your expectations of your future value and to select among your options, then your average surprise is zero. The Bayesian posterior expectation _shrinks_ the esimates $v_i$ towards the prior mean of $\mu_i$ which is what makes the procedure unbiased.

Depending of the distribution $P(V|\mu)$ the option that is selected by the Bayesian procedure (i.e., optimizing over $\hat{\mu}$) can be different from the one by optimizing over $V$. For example, if we knew that the estimate with the largest maginitude, say $v_j$, is very noisy, option $j$ may no longer be selected after the shrinkage due to the posterior expectation. An option with a smaller but more accurate estimate may win out. Therefore, you not only have unbiased estimates of the value of the decisions you make, but you also __make better decisions__. 
(It can be shown that the Bayesian procedure is guaranteed to produce decisions with greater value on average than maximizing over the estimates, unless the two procedures produce identical decisions everytime.)

**Caveat Lector**. There is a subtle sleight-of-hand in the proof of unbiasedness of the Bayesian procedure above. On the fourth line of the proof we said $E_\mu[\mu_k|V] = \hat{\mu}_k$. Note that this expectation with respect to $\mu$ is being conducted _by the universe_, whereas the expectation in $\hat{\mu}_i = E[\mu_i|V]$ to obtain the estimate was conducted _by you_. Therefore, as a quick simulation will verify, if your notion of the prior distribution on $\mu$ differs from the universe's, the guarantee of unbiasedness does not hold. Generally our belief about $\mu$ will flatter and wider (indicating our ignorance) than the true prior. In this case the optimizer's bias is not completely eliminated even with the Bayesian procedure. In this case one could apply Smith and Winkler's recommendation of a hierarchical prior, which results in the posterior estimates that shrink towards a weighted average of a global mean and the mean of the estimates $\bar{v} = \frac{1}{n}\sum_iv_i$.








