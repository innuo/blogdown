---
title: Selection Bias and the Disappointed Optimizer
author: ''
date: '2019-03-25'
slug: selection-bias-and-the-optimizers-lament
categories:
  - Optimization
tags:
  - Selection bias
---



<p><em>Wherein I introduce and explain the well-studied mechanism behind the pervasive phenomenon in life of things being just a bit worse than expected. I will walk through some of the discussion in two excellent articles, <a href="https://pdfs.semanticscholar.org/ce61/396a4abe1da265f4b5d3f05d11fd206c40f7.pdf">The Optimizer’s Curse: Skepticism and Postdecision Surprise in Decision Analysis</a> by Smith and Winkler and <a href="https://arxiv.org/pdf/1302.7175.pdf">Estimating the Maximum Expected Value: An Analysis of (Nested) Cross Validation and the Maximum Sample Average</a> by van Hasselt.</em></p>
<p>Have you noticed that the checkout lanes you choose at the grocery store tends to be slower than you expected, the products you order off Amazon disappoint, and your second dates are not as exciting as your firsts? If you have, and suspect that the universe is conspiring against you, let me assure you that your suspicions are well founded. The fundamental laws of probability have indeed been arrayed to scupper your satisfaction. If you haven’t noticed any such conspiracy, I congratulate you on either your consistent practice of Zen Buddhism or on your finely tuned skepticism about things.</p>
<p>The mechanism that may explain this seeming conspiracy, phenomena as diverse as the the replication crisis in social sciences and the oil wells producing below expectations, and also superstitions like the Sports Illustrated cover jinx is what Smith and Winker call <em>Postdecision Surprise</em>. Let’s look a bit closer at the mechanism (using notation slightly different from Smith and Winkler).</p>
<p>Imagine that you are selecting from <span class="math inline">\(n\)</span> options, <span class="math inline">\(1, \ldots, n\)</span>. Let the <em>true</em> values of these <span class="math inline">\(n\)</span> options to you be as the vector <span class="math inline">\(\mu = (\mu_1, \ldots, \mu_n)\)</span>. If these true values were known to you, then you would choose option <span class="math inline">\(m\)</span> where <span class="math inline">\(m = \mbox{argmax}_i\, \mu_i\)</span>.</p>
<p>Instead assume that you only have <em>estimates</em> (<span class="math inline">\(V = (v_1, \ldots, v_n)\)</span>) of the true values. Further assume that the estimates are <em>unbiased</em>. That is, on average each <span class="math inline">\(v_i\)</span> neither overestimates nor underestimates its corresponding true value <span class="math inline">\(\mu_i\)</span>. An obvious strategy now is for you choose to go with option <span class="math inline">\(k = \mbox{argmax}_i\, v_i\)</span>. That is, you select the option that has the largest estimate of value. After the choice is made, the true value <span class="math inline">\(\mu_k\)</span> is revealed to you. We want to know what the <em>surprise</em> <span class="math inline">\(\mu_k - v_k\)</span> is, on average.</p>
<p>We have <span class="math display">\[\mu_k - v_k \leq \mu_k - v_m \leq \mu_m - v_m\]</span> The first inequality is because <span class="math inline">\(v_k \geq v_m\)</span> (that’s why you chose option <span class="math inline">\(k\)</span>) and the second inequality is because <span class="math inline">\(\mu_m \geq \mu_k\)</span> because <span class="math inline">\(m^{th}\)</span> option is the best (unbeknowst to you.)</p>
<p>Now taking expectations with respect to <span class="math inline">\(V\)</span> we have <span class="math display">\[ E[\mu_k - v_k ] \leq E[\mu_m - v_m] = 0\]</span> The equality of the second term to zero is due to our assumption that the estimates are all (and in particular the <span class="math inline">\(m^{th}\)</span> one is) unbiased. The expected surprise is therefore non-positive. In fact, it is zero only when the probability <span class="math inline">\(P(k = m) = 1\)</span>. That is, if there is a chance that we make a wrong choice based on our estimates then the our suprises are on average unpleasant.</p>
