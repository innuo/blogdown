<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Extrapolating by Inverse Optimization | Notes To An Earlier Self</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Extrapolating by Inverse Optimization</span></h1>

<h2 class="date">2019/03/09</h2>
</div>

<main>



<p><em>Wherein I present a simple example of a prediction problem modeled as inverse optimization and its formulation as a bilevel optimization problem, with a brief detour into Bayesian estimation.</em></p>
<p>Our story begins with Alice who runs a grocery store with a small selection of locally grown produce. Alice wishes to estimate the impacts of changing the prices of her produce on the purchase behavior of her customers and wonders if the data she has been collecting over the previous year can help. After consulting with her data scientist friend she puts together a database of quantities of produce purchased by individual customers under various pricing regimes, and hands him the trove.</p>
<p>The collected data looks something like the following. (In each row the prices and quantities are for <em>all</em> the products Alice sells.)</p>
<table>
<thead>
<tr class="header">
<th align="left">Date</th>
<th align="left">Customer.ID</th>
<th align="left">Price.Vector</th>
<th align="left">Quantity.Vector</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Jan 1</td>
<td align="left">XYZ</td>
<td align="left">[$3.2, $2.5, $1.0, …]</td>
<td align="left">[1 lb, 0.0 lb, 0.0 lb, …]</td>
</tr>
<tr class="even">
<td align="left">Jan 8</td>
<td align="left">ABC</td>
<td align="left">[$2.0, $2.0, $1.5, …]</td>
<td align="left">[0.0 lb, 0.0 lb, 0.5 lb, …]</td>
</tr>
<tr class="odd">
<td align="left">Feb 4</td>
<td align="left">XYZ</td>
<td align="left">[$2.5, $2.0, $1.8, …]</td>
<td align="left">[1.0 lb, 0.0 lb, 0.1 lb, …]</td>
</tr>
<tr class="even">
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
</tr>
</tbody>
</table>
<p>The data scientist friend doesn’t see what the big problem is. He builds deep learning models in his sleep and this seems like a simple (multi-output) regression problem. He could just build a machine to predict the quantities column from the price column and take the afternoon off.</p>
<p>Alas it was not to be; the price vectors that Alice wants to plug into the trained regression model are well outside the ranges of those that she provided the data scientist for training. She does not see the point of any such modeling if it doesn’t enable extrapolation. She is appalled by the resulting nonsensical predictions, that her friend assures her were produced by algorithms indistinguishable from the ones that in the near future will drive her around town.</p>
<div id="a-physics-of-purchase-behavior" class="section level2">
<h2>A Physics of Purchase Behavior</h2>
<p>Alice decides to take a less shallow approach and write out what she knows about the problem and how it relates to what she wishes to estimate.</p>
<p>She reasons that each of her customers <span class="math inline">\(\smash{i}\)</span> has a weekly budget <span class="math inline">\(\smash{b_{i}}\)</span> for produce (<span class="math inline">\(\smash{t}\)</span> stands for the date of the store visit) and a personal produce value vector <span class="math inline">\(\smash{v_i}\)</span>. (She makes the simplifying asssumption that the budget does not vary from week to week.) Each customer may have other individual constraints on the purchases (e.g., at least <span class="math inline">\(2\)</span> lb of fruit, no more than <span class="math inline">\(5\)</span> lb of perishables.)</p>
<p>She hypothesizes that a customer on every weekly visit looks at the produce price vector <span class="math inline">\(\smash{p_t}\)</span>, and mentally runs a simple optimization of the following form to decide what quantities of each item of produce (<span class="math inline">\(x_{it}\)</span>) he will purchase:</p>
<p><span class="math display">\[\begin{aligned}
x_{it} &amp;= \mbox{arg max}_x \; v_i^T x \\
\mbox{subject to} &amp;\;\; \smash{p_t^T} x \leq b_{i} \\
&amp;\; \; A x \leq d_i
\end{aligned}
\]</span></p>
<p>The last constraint captures the notion of the customer-specific constraints mentioned above, where <span class="math inline">\(A\)</span> is assumed known (since its rows define some common purchase constraints) while the constraint bounds <span class="math inline">\(d_i\)</span> are not known.</p>
<p>The above optimization problem with a linear objective and constraints is called a <em>Linear Program</em> for which there exist very efficient solvers. Look below for a basic implementation of a linear program in R.</p>
<p>That is, if for any customer Alice knew the parameters of <em>their</em> optimization problem (<span class="math inline">\(v_i\)</span> up to a normalizing scalar, <span class="math inline">\(b_i\)</span> and <span class="math inline">\(d_i\)</span>) then predicting the purchase behavior is easy. It just involves solving the above problem for any price vector of interest <span class="math inline">\(p\)</span> to obtain a prediction of that customer’s purchase quantity vector <span class="math inline">\(x_i\)</span>. Note that, albeit esoteric, the optimizer defines a family of regression functions <span class="math inline">\(x_i = Opt(p_t; \theta)\)</span> parameterized by <span class="math inline">\(\theta \triangleq (v_i, b_i, d_i)\)</span>, in principle, no different from any other family.</p>
<p>Therefore the problem of <em>learning</em> the regressor reduces to estimating these parameters from historical prices and their associated quantity vectors. This estimation problem, because it is posed as <em>inverting</em> the optimization procedure, is studied under the heading <em>Inverse Optimization</em>.</p>
<p>(The term engineers use for such an <em>inverting</em> process, that is, estimating the parameters of a system from observations of behavior, is <em>System Identification</em>. Although many of the techniques that engineers use exploit some special structure of their systems, their <em>task</em> is exactly the same as Alice’s.)</p>
</div>
<div id="bayesianism-as-commonsense" class="section level2">
<h2>Bayesianism as Commonsense</h2>
<p>Alice first codes up the <span class="math inline">\(Opt(.)\)</span> function in the hope that when she comes up with a way to estimate the parameters, she would be ready with the prediction function. She quickly realizes that a simple approach to estimate the parameters is the following. First select some sensible ranges for the various parameters (knowing the neighborhood well she has a good sense of what reasonable budgets, value vectors etc.), sample a vector of parameters within that range and run the function <span class="math inline">\(Opt(.)\)</span> over the prices in her dataset. If the resulting predictions of the quantities are <em>close</em> to those in the data, keep the parameter vector, else discard it. We can view this procedure as sampling, followed by running the <span class="math inline">\(Opt(.)\)</span> regression function (which I will call <em>simulation</em>, because it simulates the purchase behavior), followed by filtering the samples that do not yield data close to the historical record (the observations).</p>
<p>After running this <em>sample-simulate-filter</em> process on some large number of times she will have a set of parameter vectors which produced data that looks like her database, that is, a set of parameter vectors <em>compatible</em> with her data. If this set ends up being clustered around some value (i.e., if <em>very</em> different parameter settings do not end up producing data close to the observations), then she could choose the mean of the filtered parameter set as her estimate. Problem solved.</p>
<p>In fact, she reasons, that instead of taking the mean of the filtered parameter vectors, she could use them to estimate her uncertainty in the predictions from her regression function. For a price vector that she would like to plug into her regression function, she could run the <span class="math inline">\(Opt(.)\)</span> function over a random sample of compatible parameter vectors and use the range of the predicted values as her measure of uncertainty.</p>
<p>Although Alice is unware of it, she not only independently derived the fundaments of Bayesian reasoning from commonsense, but a particular <em>computational</em> approach to Bayesian estimation. An entire subfield of Bayesian statistics, with journals, yearly conferences and other trimmings, called <em>Approximate Bayesian Computation (ABC)</em> is dedicated to Alice’s sample-simulate-filter method, with the goal of making it computationally feasible. Note how the <em>ABC</em> approach can be applied to invert any parameterized simulator, at least in principle. This generality is paid for in computational costs.</p>
<p><strong>A Quick Aside on Identifiability</strong>. <em>Identifiability</em> is a topic that statisticians like to obsess over in their work, resulting in a thicket of abstruse procedures for practitioners to follow to avoid a dull feeling of being insufficiently diligent.</p>
<p>From a Bayesian vantage the commonsense way to think about identifiability is captured in a statement made above – <em>very</em> different parameter settings do not end up producing data close to the observations. That is, if vastly different (a priori equally likely) parameter values are compatible with the data then we say that the parameters of the model are non-identifiable. In fact, in practice it is even a bit milder than that. Loosely speaking, for the kinds of extrapolations we wish to perform with the learned model (i.e, simulator + compatible parameter vectors), if the predictions on <em>any</em> input from <em>most</em> of the compatible parameter vectors are <em>similar</em>, then for practical purposes the model is identified.</p>
<p>Identifiability in a Bayesian setting is a function of the prior, the simulator, and the observed data. If we can disallow parts of the parameter space which end up being compatible with the data by some external considerations, or if we are able to collect more of the right kind of data, we can recover idenfitiability. If neither is possible, the only hope is to restrict the simulator by reparameterization and only gain partial knowledge about the system being studied, consequently allowing only a restricted type of extrapolation.</p>
</div>
<div id="saving-on-aws-costs" class="section level2">
<h2>Saving on AWS Costs</h2>
<p>As I alluded to above, the ABC procedure can be very computionally demanding when the amount of observed data or the number of parameters is large. Consequently for models (priors + simulators) for which we can know a little bit more, statisticians and engineers have come up with a host of techniques to speed up the estimation process. For example, if the simulation function is such that we can compute the <em>likelihood</em>, that is, the probability of the observations for a given parameter vector, techniques like Markov-Chain Monte Carlo (MCMC) or Variational Bayes can exploit that fact for a speedy estimation of the model posterior (which is a specification of the parameter vectors compatible with the observed data.) I won’t go any more into these techniques here than pointing to <a href="https://mlstatold.blogspot.com/2018/05/a-short-presentation-on-probabilistic.html">my presentation</a> on variational inference.</p>
</div>
<div id="finally-getting-to-the-point" class="section level2">
<h2>Finally Getting to the Point</h2>
<p>It turns out that for the particular model that Alice constructed by representing the purchase quantities as solutions of linear programs, the parameters of the model can be estimated by exploiting optimality properties of linear programs.</p>
<p>For simplicity let us assume that the measure of distance of the predictions from the simulator to the observed data is the sum of squared errors. We can now restate Alice’s parameter estimation problem as</p>
<p><span class="math display">\[\begin{aligned}
\hat{\theta}_i, \hat{x} \triangleq  (\hat{v}_i, \hat{b}_i, \hat{d}_i, \hat{x}) &amp;= \mbox{arg min}_{\theta, x} \;\sum_t{(x_{it} - q_{it})^2} \\
\mbox{subject to} &amp;\;\; x_{it} = Opt(p_t, \theta) 
\end{aligned}
\]</span>
where <span class="math inline">\(p_t\)</span> is the price for week <span class="math inline">\(t\)</span> and <span class="math inline">\(q_{it}\)</span> is the quanty vector purchased by customer <span class="math inline">\(i\)</span> that week. Note how even though we only care about an estimate for <span class="math inline">\(\theta\)</span> the optimization problem is over <span class="math inline">\(\theta\)</span> as well as <span class="math inline">\(x\)</span> (the vector of predictions of the quantities from the model).</p>
<p>Again, the above optimization problem is to choose the parameter vector <span class="math inline">\(\theta_i\)</span> (and the predictions <span class="math inline">\(x\)</span> from that parameter vector) that minimize the squared error between the predictions <span class="math inline">\(x_{it}\)</span> of the simulator and the observed quantities <span class="math inline">\(q_{it}\)</span>. The solution of this problem will yield the estimate the parameter vector for customer <span class="math inline">\(i\)</span>.</p>
<p>(Like in the discussion above if we have prior knowledge about reasonable values for the parameters or on how the parameters vary between customers, we can use this knowledge by adding cost terms into the objective. Note that this way of adding cost terms into the objective to represent prior knowledge and then minimizing the overall cost yielding a point estimate of the parameters is called <em>Maximum A Posteriori</em> estimation in Bayesian lingo.)</p>
<p>We notice that the above inverse optimization problem has a <em>nested</em> structure. The <em>inner</em> constraints are based on the <span class="math inline">\(Opt(.)\)</span> which is a linear program, i.e., an optimization problem. The problem is consequently a special case of what is called a <em>bilevel</em> optimization problem.</p>
<p>Bilevel optimization problems have the structure of an <em>outer</em> optimization problem subject to constraints dervied from an <em>inner</em> optimization problem. General bilevel optimization problems are difficult to solve but for certain special cases (which include Alice’s problem) they can be reformulated as <em>Mathematical Programs with Equilibrium Constraints (MPEC)</em>, where certain optimality conditions of the inner optimization problem are exploited to avoid the inner optimization-based constraints.</p>
<p>Let us make all this a little clearer with Alice’s example. Again her <span class="math inline">\(Opt(.)\)</span> problem is written as
<span class="math display">\[\begin{aligned}
x_{it} &amp;= \mbox{arg max}_x \; v_i^T x \\
\mbox{subject to} &amp;\;\; \smash{p_t^T} x \leq b_{i} \\
&amp;\; \; A x \leq d_i
\end{aligned}
\]</span></p>
<p>For <span class="math inline">\(x_{it}\)</span> to be the optimal solution for the above problem it <em>must</em> necessarily satisfy the <em>Karush-Kuhn-Tucker (KKT)</em> conditions which for Alice’s problem state that there must exist a scalar <span class="math inline">\(\lambda\)</span> and a vector <span class="math inline">\(\mu\)</span> (which has as many entries as there are rows in <span class="math inline">\(A\)</span>) that together with <span class="math inline">\(x_{it}\)</span> satisfy the following constraints.</p>
<p><span class="math display">\[\begin{aligned}
v_i + \lambda\, p_i + A^T \mu &amp;= 0  \\
\smash{p_t^T} x_{it} &amp;\leq b_{i} \\
A x_{it} &amp;\leq d_i \\
\lambda &amp;\geq 0 \\
\mu &amp;\geq 0 \\
\lambda (p_t^T x_{it} - b ) &amp;= 0 \\
\mu^T (A x_{it} - d_i) &amp;= 0
\end{aligned}
\]</span></p>
<p>The quantity <span class="math inline">\(\lambda\)</span> and the entries of <span class="math inline">\(\mu\)</span> are called the <em>Lagrange multipliers</em> in optimization theory, and there is one for every constraint in the problem. Note how the KKT constraints are all linear in <span class="math inline">\(x_{it}\)</span>, <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> <em>except</em> for the last two, which are called the <em>complementarity constraints</em>. (Complementary because, if <span class="math inline">\(\lambda\)</span> is non-zero then <span class="math inline">\(p_t^T - x\)</span> has to be zero and vice-versa.) They encode the notion that if at optimality a certain constraint is inactive (i.e., the constraint might as well have not been part of the original problem – it does not restrict the optimal solution), then the corresponding Lagrange multiplier has to be zero.</p>
<p>The first condition is called the <em>stationarity</em> condition, the second and third are called <em>primal feasibility</em> conditions (these are just a copy of the constraints from the original problem), and the fourth and the fifth are called <em>dual feasibility</em> conditions (the Lagrange multipliers for inequality constraints cannot be negative).</p>
<p>For a linear program the KKT conditions are not only necessary but sufficient for optimality. That is <em>if</em> we found a primal feasible <span class="math inline">\(x_{it}\)</span> and dual feasible <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> which also satisfy the stationarity and complementarity conditions, <em>then</em> <span class="math inline">\(x_{it}\)</span> is an optimal solution to the original optimization problem.</p>
<p>We can use this fact to rewrite the bilevel optimization problem. That is we can translate the problem</p>
<p><span class="math display">\[\begin{aligned}
\hat{\theta}_i, \hat{x} \triangleq  (\hat{v}_i, \hat{b}_i, \hat{d}_i, \hat{x}) &amp;= \mbox{arg min}_{\theta, x} \;\sum_t{(x_{it} - q_{it})^2} \\
\mbox{subject to} &amp;\;\; x_{it} = Opt(p_t, \theta) 
\end{aligned}
\]</span>
to an equivalent problem</p>
<p><span class="math display">\[\begin{aligned}
\hat{\theta}_i, \hat{x} \triangleq  (\hat{v}_i, \hat{b}_i, \hat{d}_i, \hat{x}) &amp;= \mbox{arg min}_{\theta, x} \;\sum_t{(x_{it} - q_{it})^2} \\
\mbox{subject to} &amp;\;\;  \\ 
&amp; v_i + \lambda\, p_i + A^T \mu = 0  \\
&amp; \smash{p_t^T} x_{it} \leq b_{i} \\
&amp; A x_{it} \leq d_i \\
&amp; \lambda \geq 0 \\
&amp; \mu \geq 0 \\
&amp; \lambda (p_t^T x_{it} - b ) = 0 \\
&amp; \mu^T (A x_{it} - d_i) = 0
\end{aligned}
\]</span></p>
<p>which is no longer a bilevel optimization problem, but, because of the two complementarity constraints, a mathematical program with equilibrium constraints (MPEC). Many techniques have been proposed to handle these constraints but conceptually the most straightfoward is to rewrite them using boolean variables, thereby converting the above problem into a <em>Mixed Integer Quadratic Program (MIQP)</em>. See below for more details on this conversion.</p>
</div>
<div id="discussion" class="section level2">
<h2>Discussion</h2>
<p>Assume that Alice was successful in accurately estimating the parameters of her model <span class="math inline">\(Opt(.)\)</span> and now wants to maximize her own profit by adjusting her price vector <span class="math inline">\(p\)</span>. One should be able to convince oneself that this problem is also a bilevel optimization problem. In fact, the interaction of her prices and the customer purchase behavior is an instance of a <em>Stackleberg game</em> that models economic scenarios with such a leader-follower dynamic. Bilevel optimization problems pop up in the study of equilibria in Stackleberg games, and have many other economic applications. While the price of fruit is important in its own right, my own interest in this topic is due to its applicability to designing optimal energy portfolios.</p>
<p>Before I conclude, I want to discuss the connection between Inverse Optimization and <em>Inverse Reinforcement Learning (IRL)</em>, which at least superficially seem like they ought to be related. IRL deals with the estimation of the reward function that an agent is optimizing by observing its behavior in an environment. This can be useful, for example, when we want to train a robot to imitate a human whose behavior we can observe but not the reward function she is optimizing.</p>
<p>To formulate Alice’s problem as IRL, we model her customers as agents who find themselves in a <em>state</em> which is the price regime set by Alice, and take an <em>action</em> which is the quanities they purchase. In order to train RL agents that behave like the customers, we would need the reward function that maps a state and action to a reward value, i.e., a function that maps a price and quantity vector to a reward. The reward function for the <span class="math inline">\(i^{th}\)</span> customer in Alice’s model be written as (where <span class="math inline">\(s\)</span> is the state and <span class="math inline">\(a\)</span> is the action)</p>
<p>\begin{aligned}
r(s, a) &amp;= {
\begin{array}{ll}
v_i^T a ;;  ;; s^T a b_i ;&amp; ;; A, a d_i \
-;; </p>
<pre><code>            \end{array}
          \right.</code></pre>
<p>\end{aligned}
IRL attempts to approximate this reward function (without assuming the functional form above) from historical data (that is, the recorded behavior of customers), which can then be used to reinforcement learn a simulator for customer behavior – essentially to reverse engineer the <span class="math inline">\(Opt(.)\)</span> function from data. In other words, the IRL way of solving Alice’s problem lies somewhere in between the regression approach and inverse optimization approach, by assuming a bit more than the former and a bit less than the latter.</p>
</div>
<div id="miscellany" class="section level2">
<h2>Miscellany</h2>
<p><strong>Linear programming in R</strong>. Example implementation of Alice’s <span class="math inline">\(Opt(.)\)</span> function.</p>
<pre class="r"><code>library(CVXR)

Opt &lt;- function(p,                  #input price vector
                v = c(0.1, 0.9),    #value vector
                b = 10,             #budget
                d = c(5, 1))        #rhs of constraints
{
  x &lt;- Variable(2)                    #only two products 

  value &lt;- sum(v * x)                 #total value that the customer optimizes
  
  constr_budget &lt;- sum(p * x) &lt;= b    #total cost no more than budget
  A &lt;- rbind(c(1, 1), c(0, 1))        #&quot;other&quot; constraint matrix
  constr_other &lt;- A %*% x &lt;= d        #other constraints
  
  #solve for value maximization
  solution &lt;- solve(Problem(Maximize(value), list(constr_budget, constr_other))) 
  return(list(status = solution$status, quantities = solution$getValue(x)))
}

sol = Opt(p = c(3, 2))               #predict quantities of the two products

cat(paste0(&#39;Status: &#39;, sol$status))
## Status: optimal
cat(paste0(round(sol$quantities, 2))) #print optimal quantity vector
## 2.67 1</code></pre>
<p><strong>A mixed-integer formulation for OR constraints (so-called “disjunctions”)</strong>.
Complementarity constraints restrict a variable to be zero whenever another is non-zero. More generally in a optimization problem over a vector <span class="math inline">\(x\)</span>, we might want to add the constraint that at least one of the two linear functions <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x)\)</span> must be zero. That is, either <span class="math inline">\(f(x) =0\)</span> or <span class="math inline">\(g(x) =0\)</span>, written as <span class="math inline">\(f(x) g(x) = 0\)</span> (a so-called <em>bilinear</em> constraint).</p>
<p>This non-linear constraint can be “linearized” by adding another variable <span class="math inline">\(z\)</span> to the optimization problem and replacing the bilinear constraint with the following constraints</p>
<p><span class="math display">\[\begin{aligned}
-Mz \leq f(x) &amp;\leq M z \\
-M(1-z) \leq g(x) &amp;\leq M (1-z) \\
z &amp;\in \{0, 1\}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(M\)</span> is some large positive number. When the binary variable <span class="math inline">\(z\)</span> takes the value <span class="math inline">\(0\)</span> the constraints restrict <span class="math inline">\(f(x)\)</span> to be identically zero and leave <span class="math inline">\(g(x)\)</span> unconstrained. When it takes the value of <span class="math inline">\(1\)</span> the reverse becomes true.</p>
<p>This trick for converting disjunctive constraints (unions of sets) into intersections is called the <em>big-M reformulation</em>.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ol style="list-style-type: decimal">
<li>Andrew Gelman, <a href="https://statmodeling.stat.columbia.edu/2014/02/12/think-identifiability-bayesian-inference/">How to think about “identifiability” in Bayesian inference?</a></li>
<li>Ahuja and Orling, <a href="https://dspace.mit.edu/bitstream/handle/1721.1/2696/SWP-4002-40939332.pdf;sequence=1">Inverse Optimization, Part 1:
Linear Programming and General Problem</a>. This paper talks about finding the cost vector <span class="math inline">\(v\)</span> of a linear programming problem given the solution. Under their particular formulation this inverse problem itself turns out be a linear program.</li>
<li>Dong and Chen, <a href="https://papers.nips.cc/paper/7294-generalized-inverse-optimization-through-online-learning.pdf">Generalized Inverse Optimization through Online
Learning</a>. This paper presents an algorithm to perform online updates to track changing parameters of an optimization problem when observations of inputs and decisions are revealed one at a time.</li>
</ol>
</div>

</main>

  <footer>
  &nbsp;
&nbsp;
<hr>
<div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://modsimopt-netlify-com.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

  
  <hr/>
  &copy; Harsha Veeramachaneni 2019. Made using  <a href="https://github.com/rstudio/blogdown">blogdown</a> &amp; <a href="https://gohugo.io/">Hugo</a>
  
  </footer>
  </body>
</html>

